<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"><title>三种方法做特征选择 | 降维Ⅰ | SLie's Blog|琴弦之轮</title><meta name="author" content="Slie"><meta name="copyright" content="Slie"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="📝本文将介绍数据挖掘&amp;amp;机器学习中特征选择的三种方法：过滤、包裹和嵌入"><link rel="shortcut icon" href="/img/%E7%A3%81%E5%B8%A6.png"><link rel="canonical" href="https://qslie.top/posts/d8f8d3bd/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//fonts.googleapis.com" crossorigin=""><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="/pluginsSrc/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="/pluginsSrc/node-snackbar/dist/snackbar.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@900&amp;display=swap" media="print" onload='this.media="all"'><script>const GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:{path:"/search.xml",preload:!0,top_n_per_article:1,unescape:!1,languages:{hits_empty:"找不到您查询的内容：${query}",hits_stats:"共找到 ${hits} 篇文章"}},translate:void 0,noticeOutdate:{limitDay:90,position:"top",messagePrev:"本文章距离上次修改已经过了",messageNext:"天，相关内容可能不再适用，请留意."},highlight:{plugin:"highlighjs",highlightCopy:!0,highlightLang:!0,highlightHeightLimit:200},copy:{success:"复制成功",error:"复制错误",noSupport:"浏览器不支持"},relativeDate:{homepage:!1,post:!0},runtime:"天",dateSuffix:{just:"刚刚",min:"分钟前",hour:"小时前",day:"天前",month:"个月前"},copyright:void 0,lightbox:"mediumZoom",Snackbar:{chs_to_cht:"你已切换为繁体",cht_to_chs:"你已切换为简体",day_to_night:"你已切换为深色模式",night_to_day:"你已切换为浅色模式",bgLight:"#49b1f5",bgDark:"#121212",position:"bottom-center"},source:{justifiedGallery:{js:"/pluginsSrc/flickr-justified-gallery/dist/fjGallery.min.js",css:"/pluginsSrc/flickr-justified-gallery/dist/fjGallery.css"}},isPhotoFigcaption:!1,islazyload:!1,isAnchor:!1,percent:{toc:!0,rightside:!1},autoDarkmode:!1}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"三种方法做特征选择 | 降维Ⅰ",isPost:!0,isHome:!1,isHighlightShrink:!1,isToc:!0,postUpdate:"2024-03-11 22:44:06"}</script><noscript><style>#nav{opacity:1}.justified-gallery img{opacity:1}#post-meta time,#recent-posts time{display:inline!important}</style></noscript><script>(e=>{e.saveToLocal={set:function(e,t,o){if(0===o)return;const n=864e5*o,a={value:t,expiry:(new Date).getTime()+n};localStorage.setItem(e,JSON.stringify(a))},get:function(e){const t=localStorage.getItem(e);if(!t)return;const o=JSON.parse(t);if(!((new Date).getTime()>o.expiry))return o.value;localStorage.removeItem(e)}},e.getScript=e=>new Promise(((t,o)=>{const n=document.createElement("script");n.src=e,n.async=!0,n.onerror=o,n.onload=n.onreadystatechange=function(){const e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(n.onload=n.onreadystatechange=null,t())},document.head.appendChild(n)})),e.getCSS=(e,t=!1)=>new Promise(((o,n)=>{const a=document.createElement("link");a.rel="stylesheet",a.href=e,t&&(a.id=t),a.onerror=n,a.onload=a.onreadystatechange=function(){const e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(a.onload=a.onreadystatechange=null,o())},document.head.appendChild(a)})),e.activateDarkMode=function(){document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")},e.activateLightMode=function(){document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#ffffff")};const t=saveToLocal.get("theme");"dark"===t?activateDarkMode():"light"===t&&activateLightMode();const o=saveToLocal.get("aside-status");void 0!==o&&("hide"===o?document.documentElement.classList.add("hide-aside"):document.documentElement.classList.remove("hide-aside"));/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)&&document.documentElement.classList.add("apple")})(window)</script><link rel="stylesheet" href="/css/custom.css" media="defer" onload='this.media="all"'><link rel="stylesheet" href="/css/fixed_comment.css" media="defer" onload='this.media="all"'><link rel="stylesheet" href="/css/twikoo_beautify.css" media="defer" onload='this.media="all"'><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/font-awesome-animation.min.css" media="defer" onload='this.media="all"'><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/tag_plugins.css" media="defer" onload='this.media="all"'><script src="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/carousel-touch.js"></script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://s1.ax1x.com/2022/04/09/Likong.png" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">182</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">98</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">45</div></a></div><hr class="custom-hr"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i> <span>声影</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/gallery/"><i class="fa-fw fas fa-images"></i> <span>相册</span></a></li><li><a class="site-page child" href="/films/"><i class="fa-fw fas fa-video"></i> <span>映像</span></a></li><li><a class="site-page child" href="/books/"><i class="fa-fw fas fa-book"></i> <span>图书</span></a></li><li><a class="site-page child" href="/games/"><i class="fa-fw fas fa-gamepad"></i> <span>游戏</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i> <span>友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i> <span>关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image:url('https://z3.ax1x.com/2021/04/17/c5iSpj.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="SLie's Blog|琴弦之轮"><span class="site-name">SLie's Blog|琴弦之轮</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i> <span>搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i> <span>声影</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/gallery/"><i class="fa-fw fas fa-images"></i> <span>相册</span></a></li><li><a class="site-page child" href="/films/"><i class="fa-fw fas fa-video"></i> <span>映像</span></a></li><li><a class="site-page child" href="/books/"><i class="fa-fw fas fa-book"></i> <span>图书</span></a></li><li><a class="site-page child" href="/games/"><i class="fa-fw fas fa-gamepad"></i> <span>游戏</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i> <span>友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i> <span>关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">三种方法做特征选择 | 降维Ⅰ</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-10-18T08:27:49.000Z" title="发表于 2023-10-18 16:27:49">2023-10-18</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-03-11T14:44:06.485Z" title="更新于 2024-03-11 22:44:06">2024-03-11</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF/">计算机科学与技术</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">机器学习与深度学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">3.2k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>10分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" data-flag-title="三种方法做特征选择 | 降维Ⅰ"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><div class="top-img gist" style="background-image:url(https://z3.ax1x.com/2021/04/17/c5iSpj.jpg)"></div><article class="post-content" id="article-container"><h2 id="引言">引言</h2><p><strong>特征选择</strong>，也称特征子集选择，是指从<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.6833em"></span><span class="mord mathnormal" style="margin-right:.10903em">M</span></span></span></span> 个特征中选择<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.6833em"></span><span class="mord mathnormal" style="margin-right:.10903em">N</span></span></span></span> 个特征参与机器学习模型训练，以使模型的性能有所提升，同时，特征选择也降低特征维度，提升了模型的计算效率。<br>可以说，特征选择提取出了更易于理解的特征，挖掘了底层数据中隐藏的有用信息。毕竟特征越多，并不直接意味着其性能会变好，反之会使模型更复杂，训练时间更长，带来“维度灾难”。</p><p>根据特征选择的形式可以将特征选择方法分为3种：</p><ul><li>Filter：过滤法。按照发散性或者相关性对各个特征进行评分，设定阈值或者待选择特征的个数，选择特征。</li><li>Wrapper：包裹法。根据目标函数（通常是预测效果评分），每次选择若干特征，或者排除若干特征。</li><li>Embedded：嵌入法。先使用某些机器学习的算法和模型进行训练，得到各个特征的权值系数，根据系数从大到小选择特征。类似于Filter方法，区别是嵌入法是通过训练来确定特征优劣的。</li></ul><h2 id="过滤法-Filter">过滤法|Filter</h2><p>Filter，即过滤法，也叫筛选法。故名思议就是对大量已有的特征在训练之前做筛选的方法，显然此过程与后序学习器无关。过滤法的评估手段一般是判断单维特征与目标变量之间的关系。</p><h3 id="方差过滤">方差过滤</h3><p>方差的统计学意义表征的是<strong>数据分布的“发散”程度</strong>，即方差越大数据分布越不集中。<br>在特征选择中，我们往往认为如果特征分布相对集中，即特征取值差异不大，则其对分类器的贡献值相对较小。因此我们可以设定方差的一个<strong>阈值</strong>，将方差较小的特征剔除掉。</p><p><code>scikit-learn</code> 中的 <code>VarianceThreshold</code> 选择器可用来处理此任务：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> VarianceThreshold</span><br><span class="line"></span><br><span class="line">vt = VarianceThreshold(<span class="number">3</span>) <span class="comment">#可传入阈值参数</span></span><br><span class="line">X1 = vt.fit(X) <span class="comment">#进行过滤</span></span><br><span class="line"></span><br><span class="line">var_thd = pd.DataFrame(vt.variances_, </span><br><span class="line">					   columns = [<span class="string">&quot;Variance&quot;</span>], </span><br><span class="line">					   index = features)</span><br><span class="line">var_thd = var_thd.reset_index()</span><br><span class="line">var_thd = var_thd.sort_values(<span class="string">&#x27;Variance&#x27;</span>, ascending = <span class="number">0</span>) <span class="comment">#可打印查看</span></span><br><span class="line"></span><br><span class="line">X_new = vt.transform(X) <span class="comment">#留下的数据</span></span><br><span class="line">featrues_new = vt.get_feature_names_out() <span class="comment">#被留下特征的字符名称</span></span><br><span class="line">X_new =  pd.DataFrame(X_new, columns = features_new) <span class="comment">#可打印查看</span></span><br></pre></td></tr></table></figure><div class="note default modern"><p>阈值Threshold 可以有很多选择，如：特征中位数 <code>np.median(x.var.valuse)</code>；特征除以特征均值：<code>x/x.mean</code> ；方差均值 <code>x.var().mean()</code>等.</p></div><h3 id="卡方过滤">卡方过滤</h3><p>卡方过滤是专门针对离散型标签（即<strong>分类问题</strong>）的<strong>相关性</strong>过滤。</p><p>卡方统计量反映的是实际频数和理论频数的吻合度，在特征工程中也就是说特征与标签的相关性情况，我们希望被选择的特征与标签之间的卡方统计量更大。</p><p>卡方检验类 <code>feature_selection.chi2</code> 计算每个非负特征和标签之间的卡方统计量，并依照卡方统计量由高到低为特征排名。<br>结合 <code>feature_selection.SelectKBest</code>， 可以根据输入的”评分标准“来选出前K个分数最高的特征。<br>于是我们可以借此剔除最可能独立于标签，与我们分类目的无关的特征：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectKBest</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> chi2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用SelectKBest转换器类，用卡方函数打分</span></span><br><span class="line">chi2er = SelectKBest(score_func = chi2, k = <span class="number">10</span>)</span><br><span class="line">chi2er.fit(X, y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 得分情况</span></span><br><span class="line">scores = pd.DataFrame(chi2er.scores_, columns = [<span class="string">&quot;Scores&quot;</span>], index = features)</span><br><span class="line">scores = scores.reset_index()</span><br><span class="line">scores = scores.sort_values(<span class="string">&#x27;Scores&#x27;</span>, ascending = <span class="number">0</span>) <span class="comment">#可打印查看</span></span><br><span class="line"></span><br><span class="line">X_new = chi2er.transform(X) <span class="comment">#留下的数据</span></span><br><span class="line">features_new = chi2er.get_feature_names_out() <span class="comment">#被留下特征的字符名称</span></span><br><span class="line">X_new =  pd.DataFrame(X_new, columns = features_new) <span class="comment">#可打印查看</span></span><br></pre></td></tr></table></figure><h3 id="ANOVA过滤">ANOVA过滤</h3><p>与卡方检验类似的还有 F 检验，又称ANOVA，方差齐性检验。它可以用来捕捉每个特征与标签之间的线性关系，可以做回归也可以做分类。<br>在<code>scikit-learn</code> 中包含两个类：</p><ol><li><code>feature_selection.f_classif</code>(分类)</li><li><code>feature_selection.f_regression</code>(回归)</li></ol><p>其过滤方法与卡方分布一样。</p><h3 id="互信息过滤">互信息过滤</h3><p>互信息法是用来捕捉每个特征与标签之间的任意关系(<strong>包括线性和非线性</strong>关系)的过滤方法。<br>和F检验相似，它既可以做回归也可以做分类，在<code>scikit-learn</code> 中包含两个类：</p><ol><li><code>feature_selection.mutual_info_classif</code>(分类)</li><li><code>feature_selection.mutual_info_regression</code>(回归)</li></ol><p>这两个类的用法和参数都和F检验一模一样，不过互信息法比F检验更加强大，F检验只能够找出线性关系，而互信息法可以找出任意关系。</p><h3 id="Pearson相关系数">Pearson相关系数</h3><p>可以直接利用 <code>pandas.DataFrame.corr()</code> 计算得到各变量之间的相关系数。<br>当然为了与前面几种方法对应，我们也可以利用 <code>scipy.stats.pearsonr</code> 结合 <code>feature_selection.SelectKBest</code>进行选择。为此我们需要封装一个函数用于实现对多列的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>=</mo><mo stretchy="false">[</mo><msub><mi>X</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>X</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>X</mi><mi>n</mi></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">X=[X_1,X_2,...,X_n]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.6833em"></span><span class="mord mathnormal" style="margin-right:.07847em">X</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal" style="margin-right:.07847em">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:-.0785em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07847em">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:-.0785em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.1667em"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07847em">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.1514em"><span style="top:-2.55em;margin-left:-.0785em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span> 分别计算其与<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.1944em"></span><span class="mord mathnormal" style="margin-right:.03588em">y</span></span></span></span> 的相关系数的函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">multi_pearsonr</span>(<span class="params">X, y</span>): </span><br><span class="line">    <span class="comment"># 创建scores和pvalues数组，遍历数据集的每一列。</span></span><br><span class="line">    scores, pvalues = [], []</span><br><span class="line">    <span class="keyword">for</span> column <span class="keyword">in</span> <span class="built_in">range</span>(X.shape[<span class="number">1</span>]):</span><br><span class="line">    <span class="comment"># 只计算该列的皮尔逊相关系数和p值，并将其存储到相应数组中。</span></span><br><span class="line">        cur_score, cur_p = pearsonr(X[:,column], y)</span><br><span class="line">        scores.append(<span class="built_in">abs</span>(cur_score))</span><br><span class="line">        pvalues.append(cur_p)</span><br><span class="line">    <span class="keyword">return</span> (np.array(scores), np.array(pvalues))</span><br></pre></td></tr></table></figure><p>然后就能用相同的方法实现 top K 的特征选择了：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">m_pearsonr = SelectKBest(score_func=multi_pearsonr, k=<span class="number">10</span>) </span><br><span class="line">X_pearson = m_pearsonr.fit_transform(X, y) </span><br></pre></td></tr></table></figure><h3 id="方差膨胀系数">方差膨胀系数</h3><p><strong>方差膨胀系数(variance inflation factor，VIF)</strong> 是衡量多元线性回归模型中<strong>多重共线性(multicollinearity)</strong> 严重程度的一种度量。它表示回归系数估计量的方差与假设自变量间不线性相关时方差相比的比值。</p><p>多重共线性是指自变量之间存在线性相关关系，即一个自变量可以是其他一个或几个自变量的线性组合。</p><p>通常以 <code>10</code>作为判断边界：</p><ul><li>当<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mi>I</mi><mi>F</mi><mo>&lt;</mo><mn>10</mn></mrow><annotation encoding="application/x-tex">VIF&lt;10</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.7224em;vertical-align:-.0391em"></span><span class="mord mathnormal" style="margin-right:.22222em">V</span><span class="mord mathnormal" style="margin-right:.07847em">I</span><span class="mord mathnormal" style="margin-right:.13889em">F</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:.6444em"></span><span class="mord">10</span></span></span></span> 时，不存在多重共线性；</li><li>当<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>10</mn><mo>≤</mo><mi>V</mi><mi>I</mi><mi>F</mi><mo>&lt;</mo><mn>100</mn></mrow><annotation encoding="application/x-tex">10\leq VIF&lt;100</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.7804em;vertical-align:-.136em"></span><span class="mord">10</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:.7224em;vertical-align:-.0391em"></span><span class="mord mathnormal" style="margin-right:.22222em">V</span><span class="mord mathnormal" style="margin-right:.07847em">I</span><span class="mord mathnormal" style="margin-right:.13889em">F</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:.6444em"></span><span class="mord">100</span></span></span></span> 时，存在较强的多重共线性；</li><li>当<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mi>I</mi><mi>F</mi><mo>≥</mo><mn>100</mn></mrow><annotation encoding="application/x-tex">VIF\geq100</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8193em;vertical-align:-.136em"></span><span class="mord mathnormal" style="margin-right:.22222em">V</span><span class="mord mathnormal" style="margin-right:.07847em">I</span><span class="mord mathnormal" style="margin-right:.13889em">F</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:.6444em"></span><span class="mord">100</span></span></span></span> 时，存在严重多重共线性。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> statsmodels.stats.outliers_influence <span class="keyword">import</span> variance_inflation_factor </span><br><span class="line"></span><br><span class="line">vif = pd.DataFrame()</span><br><span class="line">vif[<span class="string">&#x27;Features&#x27;</span>] = feature_cols</span><br><span class="line">vif[<span class="string">&#x27;vif&#x27;</span>] = [variance_inflation_factor(X.values, i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(X.shape[<span class="number">1</span>])] </span><br></pre></td></tr></table></figure><p>一般来说，我们要提出过大 VIF 的特征。</p><h3 id="Fisher得分">Fisher得分</h3><p>Fisher得分是一种基于距离的特征选择方法，Fisher得分越大，该特征的分类能力越强，说明该特征可以使得分类时类内部距离尽量小，类间距离尽可能大。</p><p>实现方法详见下面给出的这个项目。</p><div class="note primary modern"><p>🚀【推荐】特征选择开源项目：<a target="_blank" rel="noopener" href="https://github.com/jundongl/scikit-feature">https://github.com/jundongl/scikit-feature</a></p></div><h2 id="包裹法-Wrapper">包裹法|Wrapper</h2><p>包裹式特征选择法的特征选择过程<strong>与学习器相关</strong>，使用学习器的性能作为特征选择的评价准则，选择出最有利于学习器性能的特征子集。</p><p>特征子集的产生方式分为<strong>前向搜索</strong>与<strong>后向搜索</strong>两种方法，在实现上，常见的方法有：</p><ol><li>稳定性选择(Stability Selection)</li><li>递归特征消除(Recursive Feature Elimination)</li></ol><div class="note default modern"><p>这两种方法也被称为 <strong>顶层特征选择算法</strong>。因为它们都需要有特定的机器学习模型作为支撑。</p></div><h3 id="递归特征消除RFE">递归特征消除RFE</h3><p><strong>递归特征消除(Recursive Feature Elimination, RFE)</strong> 的主要思想是，反复构建模型，然后选出其中贡献最差的特征，把选出的特征剔除，然后在剩余特征上继续重复这个过程，直到所有特征都已遍历。这是一种采用了贪心策略的<strong>后向搜索</strong>方法。</p><p>在 <code>scikit-learn</code> 中封装了 RFE：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">sklearn</span>.feature_selection.RFE(estimator, n_features_to_select=<span class="literal">None</span>, step=<span class="number">1</span>, verbose=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>其中的参数：</p><ul><li><code>estimator</code> – 基学习器</li><li><code>n_features_to_select</code> – 经过特征选择后，特征集中剩余的特征个数</li><li><code>step</code> – 默认<code>1</code>，即每次迭代移除一个特征</li><li><code>verbose</code> – 默认<code>0</code>，不显示中间过程</li></ul><p>RFE 的稳定性很大程度上取决于迭代时，底层使用的预测模型。如果 RFE 采用的是普通的逻辑回归，没有经过正则化的回归是不稳定的，因此 RFE 也不稳定。若采用的是脊回归 Ridge 或 Lasso，则 RFE 稳定。</p><h3 id="结合交叉验证的递归特征消除RFECV">结合交叉验证的递归特征消除RFECV</h3><p>RFE 提供了设定 <code>n_features_to_select</code> 的能力，但是保留特征的数量其实是存在一定的盲目性的，这可能使得模型性能变差。<br>比如，<code>n_features_to_select</code>过小时，相关特征可能被移除特征集，信息丢失；<code>n_features_to_select</code>过大时，无关特征没有被移除特征集，信息冗余。</p><p>在工程实践中，RFE通过CV(交叉验证)寻找最优的<code>n_features_to_select</code>，即RFECV。</p><p><code>scikit-learn</code>中RFECV的主要参数为：</p><ul><li><code>estimator</code> – 基学习器</li><li><code>step</code> – 默认<code>1</code>，即每次迭代移除一个特征</li><li><code>cv</code> – 默认<code>2</code>，即二折交叉验证的方式进行特征选择</li><li><code>scoring</code> – 根据学习目标设定的模型评分标准</li><li><code>verbose</code> – 默认<code>0</code>，即不显示中间过程</li><li><code>n_jobs</code> – 默认<code>1</code>，即不使用并行计算，单核计算</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> RFECV</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line">rfecv = RFECV(estimator=DecisionTreeClassifier()) <span class="comment">#以决策树为例</span></span><br><span class="line">rfecv.fit(X, y)</span><br><span class="line"><span class="built_in">print</span>(rfecv.support_) <span class="comment">#返回bool列表，表明哪些特征被保留</span></span><br><span class="line">X_new = X.loc[:, results.support_]</span><br></pre></td></tr></table></figure><h3 id="稳定性选择">稳定性选择</h3><p><strong>稳定性选择(Stability Selection)</strong> 是基于重新抽样技术的特征选择方法。其基本思想是：对原始数据进行多次抽样，每次生成的子样本上进行特征选择，然后统计各个特征被选为&quot;重要&quot;的频率，最终确定那些在大多数子样本中都被认为是&quot;重要&quot;的特征。</p><p>稳定性选择不仅可以用来评估特征的重要性，而且由于其基于重新抽样的特性，它还能评估特征选择结果的稳定性，也就是说，对于一个特定的选择方法，其选择结果在不同数据样本上的变动程度。</p><p><code>scikit-learn</code> 在随机LASSO和随机逻辑回归中封装了对稳定性选择的实现。</p><h2 id="嵌入法-Embedded">嵌入法|Embedded</h2><p>有些机器学习方法本身就具有对特征进行打分的机制，特征排序模型和机器学习模型是耦合在一起的。<br>在模型训练的过程中，更重要的特征自动获得了更大的权重，通过获取这些权重，就可以得到不同特征的重要性分数。</p><p>所以，通过模型机制获得重要性并以此进行特征选择的方法就是嵌入法，这种方法速度快，也易出效果，但需较深厚的<strong>先验知识</strong>调节模型。</p><h3 id="回归模型系数">回归模型系数</h3><p>我们知道线性回归模型可以看作一个多项式，其中每一项的系数可以表征这一维特征的重要程度，越是重要的特征在模型中对应的系数(绝对值)就会越大，而跟输出变量越是无关的特征对应的系数越接近于零。</p><p>因此，可以将回归模型系数视为对特征的打分，从而进行特征选择。</p><h3 id="正则化模型">正则化模型</h3><p>我们知道正则化是指对机器学习模型的不同参数增加惩罚或惩罚，以减少模型的自由度，从而避免过度拟合。</p><p>对线性模型实施<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mn>1</mn></mrow><annotation encoding="application/x-tex">L1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.6833em"></span><span class="mord mathnormal">L</span><span class="mord">1</span></span></span></span> 正则化的模型我们也叫 <strong>LASSO 回归模型</strong>。因为它在损失函数中添加了一个与系数绝对值有关的项，可以将一些特征的系数压缩为0，于是就可以通过检查哪些特征的系数被压缩到0来进行特征选择。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Lasso</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectFromModel</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">scaler.fit(X)</span><br><span class="line">stdX = scaler.transform(X) <span class="comment">#对特征进行尺度归一化</span></span><br><span class="line"></span><br><span class="line">sel_ = SelectFromModel(Lasso(alpha=<span class="number">0.03</span>))</span><br><span class="line">sel_.fit(stdX, y)</span><br><span class="line"></span><br><span class="line">features_new = X.columns[(sel_.get_support())]</span><br><span class="line">X_new = X[features]</span><br></pre></td></tr></table></figure><p>NOTE：线性模型无法解决相互之间不独立的特征，即是“多重共线性”，对离群点或噪声较为敏感。不过施加<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">L2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.6833em"></span><span class="mord mathnormal">L</span><span class="mord">2</span></span></span></span> 正则化的 Ridge 回归（岭回归）可以更好地处理这种情况。</p><h2 id="参考">参考</h2><ol><li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/405559417">特征选择与提取最全总结之过滤法 - 知乎</a></li><li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/331730202">熟练掌握这3种特征选择方法，模型性能至少提升20%</a></li><li><a target="_blank" rel="noopener" href="https://blog.csdn.net/wsyjx201448030108/article/details/129676972">特征选择系列-01-过滤式详解-从原理到应用_过滤式特征选择-CSDN</a></li><li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/wanglei5205/p/8977467.html">【特征选择】包裹式特征选择法 - wanglei5205 - 博客园</a></li><li><a target="_blank" rel="noopener" href="https://blog.csdn.net/yanhx1204/article/details/79448056">结合Scikit-learn介绍几种常用的特征选择方法-CSDN</a></li><li><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_50966476/article/details/131868748">机器学习——特征选择方法大总结-CSDN博客</a></li><li><a target="_blank" rel="noopener" href="https://www.huaxiaozhuan.com/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0/chapters/8_feature_selection.html">8_feature_selection_华校专</a></li></ol></article><div class="post-copyright"><div class="post-copyright__title"><span class="post-copyright-info"><h>三种方法做特征选择 | 降维Ⅰ</h></span></div><div class="post-copyright__type"><span class="post-copyright-info"><a href="https://qslie.top/posts/d8f8d3bd/">https://qslie.top/posts/d8f8d3bd/</a></span></div><div class="post-copyright-m"><div class="post-copyright-m-info"><div class="post-copyright-a"><h>作者</h><div class="post-copyright-cc-info"><h>Slie</h></div></div><div class="post-copyright-c"><h>发布于</h><div class="post-copyright-cc-info"><h>2023-10-18</h></div></div><div class="post-copyright-u"><h>更新于</h><div class="post-copyright-cc-info"><h>2024-03-11</h></div></div><div class="post-copyright-c"><h>许可协议</h><div class="post-copyright-cc-info"><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a rel="noopener" target="_blank" title="CC BY-NC-SA 4.0" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a></div></div></div></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><a class="post-meta__tags" href="/tags/Python/">Python</a><a class="post-meta__tags" href="/tags/%E9%99%8D%E7%BB%B4/">降维</a><a class="post-meta__tags" href="/tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/">特征工程</a></div><div class="post_share"><div class="social-share" data-image="https://z3.ax1x.com/2021/04/17/c5iSpj.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="/pluginsSrc/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="/pluginsSrc/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><link rel="stylesheet" href="/css/coin.css" media="defer" onload='this.media="all"'><div class="post-reward"><button class="tip-button reward-button"><span class="tip-button__text">打赏</span><div class="coin-wrapper"><div class="coin"><div class="coin__middle"></div><div class="coin__back"></div><div class="coin__front"></div></div></div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat.png" target="_blank"><img class="post-qr-code-img" src="/img/wechat.png"></a><div class="post-qr-code-desc"></div></li><li class="reward-item"><a href="/img/alipay.png" target="_blank"><img class="post-qr-code-img" src="/img/alipay.png"></a><div class="post-qr-code-desc"></div></li></ul></div></button></div><audio id="coinAudio" src="https://npm.elemecdn.com/akilar-candyassets@1.0.16/audio/coin.mp3"></audio><script defer src="/js/coin.js"></script><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/5f612099/" title="非负矩阵分解 | 降维Ⅲ"><img class="cover" src="https://jsd.onmicrosoft.cn/gh/SlieFamily/TempImages@main//Auto/202310201530717.png" onerror='onerror=null,src="/img/404.jpg"' alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">非负矩阵分解 | 降维Ⅲ</div></div></a></div><div class="next-post pull-right"><a href="/posts/edc91501/" title="利用位置活动基元(LAMs)挖掘工作日与周末的联系"><img class="cover" src="https://jsd.onmicrosoft.cn/gh/SlieFamily/TempImages@main//Auto/202310172058663.png" onerror='onerror=null,src="/img/404.jpg"' alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">利用位置活动基元(LAMs)挖掘工作日与周末的联系</div></div></a></div></nav><hr class="custom-hr"><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i> <span>评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://s1.ax1x.com/2022/04/09/Likong.png" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"></div><div class="author-info__name">Slie</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">182</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">98</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">45</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/sliefamily"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://qm.qq.com/cgi-bin/qm/qr?k=1hPHFQqPhpkbBVYbFjRC4q8YQ-A72EFL&amp;noverify=0" target="_blank" title="QQ"><i class="fab fa-qq"></i></a><a class="social-icon" href="https://github.com/SlieFamily" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:sliewdyinwhite@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">秘密基地被发现啦！QAQ</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%95%E8%A8%80"><span class="toc-number">1.</span> <span class="toc-text">引言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BF%87%E6%BB%A4%E6%B3%95-Filter"><span class="toc-number">2.</span> <span class="toc-text">过滤法|Filter</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%B9%E5%B7%AE%E8%BF%87%E6%BB%A4"><span class="toc-number">2.1.</span> <span class="toc-text">方差过滤</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%A1%E6%96%B9%E8%BF%87%E6%BB%A4"><span class="toc-number">2.2.</span> <span class="toc-text">卡方过滤</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ANOVA%E8%BF%87%E6%BB%A4"><span class="toc-number">2.3.</span> <span class="toc-text">ANOVA过滤</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%92%E4%BF%A1%E6%81%AF%E8%BF%87%E6%BB%A4"><span class="toc-number">2.4.</span> <span class="toc-text">互信息过滤</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Pearson%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0"><span class="toc-number">2.5.</span> <span class="toc-text">Pearson相关系数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%B9%E5%B7%AE%E8%86%A8%E8%83%80%E7%B3%BB%E6%95%B0"><span class="toc-number">2.6.</span> <span class="toc-text">方差膨胀系数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Fisher%E5%BE%97%E5%88%86"><span class="toc-number">2.7.</span> <span class="toc-text">Fisher得分</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8C%85%E8%A3%B9%E6%B3%95-Wrapper"><span class="toc-number">3.</span> <span class="toc-text">包裹法|Wrapper</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%80%92%E5%BD%92%E7%89%B9%E5%BE%81%E6%B6%88%E9%99%A4RFE"><span class="toc-number">3.1.</span> <span class="toc-text">递归特征消除RFE</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%93%E5%90%88%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E7%9A%84%E9%80%92%E5%BD%92%E7%89%B9%E5%BE%81%E6%B6%88%E9%99%A4RFECV"><span class="toc-number">3.2.</span> <span class="toc-text">结合交叉验证的递归特征消除RFECV</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A8%B3%E5%AE%9A%E6%80%A7%E9%80%89%E6%8B%A9"><span class="toc-number">3.3.</span> <span class="toc-text">稳定性选择</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B5%8C%E5%85%A5%E6%B3%95-Embedded"><span class="toc-number">4.</span> <span class="toc-text">嵌入法|Embedded</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E7%B3%BB%E6%95%B0"><span class="toc-number">4.1.</span> <span class="toc-text">回归模型系数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AD%A3%E5%88%99%E5%8C%96%E6%A8%A1%E5%9E%8B"><span class="toc-number">4.2.</span> <span class="toc-text">正则化模型</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E8%80%83"><span class="toc-number">5.</span> <span class="toc-text">参考</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/posts/d3d469f8/" title="Docker - 一步到位的应用部署与上线"><img src="https://jsd.onmicrosoft.cn/gh/SlieFamily/TempImages@main//Auto/docker.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="Docker - 一步到位的应用部署与上线"></a><div class="content"><a class="title" href="/posts/d3d469f8/" title="Docker - 一步到位的应用部署与上线">Docker - 一步到位的应用部署与上线</a><time datetime="2024-03-05T07:11:45.000Z" title="发表于 2024-03-05 15:11:45">2024-03-05</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/c1bb1ae1/" title="GFS - 谷歌的分布式文件存储系统"><img src="http://img.49you.com/20170303/58b8d6f32d651.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="GFS - 谷歌的分布式文件存储系统"></a><div class="content"><a class="title" href="/posts/c1bb1ae1/" title="GFS - 谷歌的分布式文件存储系统">GFS - 谷歌的分布式文件存储系统</a><time datetime="2024-03-05T04:04:07.000Z" title="发表于 2024-03-05 12:04:07">2024-03-05</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/f21b6bc8/" title="HuskyLab Servers 0x519 操作指南【自用】"><img src="https://jsd.onmicrosoft.cn/gh/SlieFamily/TempImages@main//Auto/husklab_bg.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="HuskyLab Servers 0x519 操作指南【自用】"></a><div class="content"><a class="title" href="/posts/f21b6bc8/" title="HuskyLab Servers 0x519 操作指南【自用】">HuskyLab Servers 0x519 操作指南【自用】</a><time datetime="2024-03-04T13:29:31.000Z" title="发表于 2024-03-04 21:29:31">2024-03-04</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/f7dae821/" title="【快速入门】集群资源管理调度系统 - Slurm"><img src="https://gitee.com/sliewdy/ImageURL-slie/raw/master/imagesNoT/QQ%E5%9B%BE%E7%89%8720210414005713.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="【快速入门】集群资源管理调度系统 - Slurm"></a><div class="content"><a class="title" href="/posts/f7dae821/" title="【快速入门】集群资源管理调度系统 - Slurm">【快速入门】集群资源管理调度系统 - Slurm</a><time datetime="2024-03-04T12:50:38.000Z" title="发表于 2024-03-04 20:50:38">2024-03-04</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/8cb817a9/" title="【最优化】Levenberg-Marquardt 算法"><img src="https://jsd.onmicrosoft.cn/gh/SlieFamily/TempImages@main//Auto/202401051550627.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="【最优化】Levenberg-Marquardt 算法"></a><div class="content"><a class="title" href="/posts/8cb817a9/" title="【最优化】Levenberg-Marquardt 算法">【最优化】Levenberg-Marquardt 算法</a><time datetime="2023-12-22T03:07:39.000Z" title="发表于 2023-12-22 11:07:39">2023-12-22</time></div></div></div></div></div></div></main><footer id="footer" style="background-image:url('https://z3.ax1x.com/2021/04/17/c5iSpj.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2024 By Slie</div><div class="framework-info"><span>框架</span> <a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题</span> <a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Welcome to Chaos World!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/pluginsSrc/medium-zoom/dist/medium-zoom.min.js"></script><script src="/pluginsSrc/instant.page/instantpage.js" type="module"></script><script src="/pluginsSrc/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn(){"object"==typeof pangu?pangu.autoSpacingPage():getScript("/pluginsSrc/pangu/dist/browser/pangu.min.js").then((()=>{pangu.autoSpacingPage()}))}function panguInit(){GLOBAL_CONFIG_SITE.isPost&&panguFn()}document.addEventListener("DOMContentLoaded",panguInit)</script><div class="js-pjax"><link rel="stylesheet" href="/pluginsSrc/katex/dist/katex.min.css"><script src="/pluginsSrc/katex/dist/contrib/copy-tex.min.js"></script><script>document.querySelectorAll("#article-container span.katex-display").forEach((a=>{btf.wrap(a,"div",{class:"katex-wrap"})}))</script><script>(()=>{const e=document.querySelectorAll("#article-container .mermaid-wrap");if(0===e.length)return;const t=()=>{window.loadMermaid=!0;const t="dark"===document.documentElement.getAttribute("data-theme")?"dark":"default";Array.from(e).forEach(((e,n)=>{const d=e.firstElementChild,r="mermaid-"+n,a="%%{init:{ 'theme':'"+t+"'}}%%\n"+d.textContent,i=mermaid.render(r,a);var m;"string"==typeof i?(m=i,d.insertAdjacentHTML("afterend",m)):i.then((({svg:e})=>{d.insertAdjacentHTML("afterend",e)}))}))},n=()=>{window.loadMermaid?t():getScript("/pluginsSrc/mermaid/dist/mermaid.min.js").then(t)};btf.addModeChange("mermaid",t),window.pjax?n():document.addEventListener("DOMContentLoaded",n)})()</script><script>(()=>{const t=()=>{twikoo.init(Object.assign({el:"#twikoo-wrap",envId:"https://twikoo.qslie.top/",region:"",onCommentLoaded:function(){btf.loadLightbox(document.querySelectorAll("#twikoo .tk-content img:not(.tk-owo-emotion)"))}},null)),GLOBAL_CONFIG_SITE.isPost&&(()=>{const t=document.getElementById("twikoo-count");t&&twikoo.getCommentsCount({envId:"https://twikoo.qslie.top/",region:"",urls:[window.location.pathname],includeReply:!1}).then((function(o){t.textContent=o[0].count})).catch((function(t){console.error(t)}))})()},o=()=>{"object"!=typeof twikoo?getScript("/pluginsSrc/twikoo/dist/twikoo.all.min.js").then(t):setTimeout(t,0)};btf.loadComment(document.getElementById("twikoo-wrap"),o)})()</script></div><script async src="/js/diytitle.js"></script><script async src="//at.alicdn.com/t/font_2264842_3izu8i5eoc2.js"></script><script async src="/js/diytitle.js"></script><script data-pjax defer src="/js/fixed_comment.js"></script><canvas class="fireworks" mobile="false"></canvas><script src="/pluginsSrc/butterfly-extsrc/dist/fireworks.min.js"></script><script id="canvas_nest" defer color="0,0,255" opacity="0.7" zindex="-1" count="99" mobile="false" src="/pluginsSrc/butterfly-extsrc/dist/canvas-nest.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i> <span>数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div><script data-pjax>if(document.getElementById("recent-posts")&&"/"===location.pathname){var parent=document.getElementById("recent-posts"),child='<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="https://qslie.top/tags/算法/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 算法相关，编程实现 (60)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://qslie.top/tags/故事/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📒 杂谈日志，光影记录 (6)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://qslie.top/tags/日常/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">💡 记忆碎片，梦境显影 (36)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://qslie.top/tags/机器学习/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">💻 机器学习，数学规划 (35)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><a class="magnet_link_more"  href="https://qslie.top/tags" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';console.log("已挂载magnet"),parent.insertAdjacentHTML("afterbegin",child)}</script><style>#catalog_magnet{flex-wrap:wrap;display:flex;width:100%;justify-content:space-between;padding:10px 10px 0 10px;align-content:flex-start}.magnet_item{flex-basis:calc(50% - 5px);background:#f2f2f2;margin-bottom:10px;border-radius:8px;transition:all .2s ease-in-out}.magnet_item:hover{background:#b30070}.magnet_link_more{color:#555}.magnet_link{color:#000}.magnet_link:hover{color:#fff}@media screen and (max-width:600px){.magnet_item{flex-basis:100%}}.magnet_link_context{display:flex;padding:10px;font-size:16px;transition:all .2s ease-in-out}.magnet_link_context:hover{padding:10px 20px}</style><style></style><script data-pjax>function butterfly_swiper_injector_config(){var s=document.getElementById("recent-posts");console.log("已挂载butterfly_swiper"),s.insertAdjacentHTML("afterbegin",'<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="posts/4f5fd499/" alt=""><img width="48" height="48" src="https://jsd.onmicrosoft.cn/gh/SlieFamily/TempImages@main//Auto/20231030204417.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-03-11</span><a class="blog-slider__title" href="posts/4f5fd499/" alt="">Deep Neural Net | 多层感知机与神经网络入门</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="posts/4f5fd499/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="posts/9a95977b/" alt=""><img width="48" height="48" src="math-cover.jfif" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-03-11</span><a class="blog-slider__title" href="posts/9a95977b/" alt="">SLie的&quot;数学基础&quot;集装箱|Perhaps.Ver1.04</a><div class="blog-slider__text">好了，你已经学会1+1=2了，下面来证明一下广义黎曼猜想吧~</div><a class="blog-slider__button" href="posts/9a95977b/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="posts/4ea9ab3c/" alt=""><img width="48" height="48" src="https://jsd.onmicrosoft.cn/gh/SlieFamily/TempImages@main/Auto/202202232045587.jpeg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-03-11</span><a class="blog-slider__title" href="posts/4ea9ab3c/" alt="">算法分析与设计 &amp; 本站算法综述</a><div class="blog-slider__text">本文罗列了常见的经典问题和算法，以及主要的算法分析方法和设计方法</div><a class="blog-slider__button" href="posts/4ea9ab3c/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="posts/5ebaa4d9/" alt=""><img width="48" height="48" src="https://gitee.com/sliewdy/ImageURL-slie/raw/master/imagesNoT/QQ%E5%9B%BE%E7%89%8720210414005713.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-03-11</span><a class="blog-slider__title" href="posts/5ebaa4d9/" alt="">捣鼓程序时的各种【踩坑】【报错】全收录</a><div class="blog-slider__text">配置环境、安装库包等网上冲浪时遇见到的各式各样奇奇怪怪的Warning和Error，以及各种治标不治本或者又治标又治本的解决方案全记录（个人向）</div><a class="blog-slider__button" href="posts/5ebaa4d9/" alt="">详情   </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>')}for(var elist="undefined".split(","),cpage=location.pathname,epage="/",flag=0,i=0;i<elist.length;i++)cpage.includes(elist[i])&&flag++;("all"===epage&&0==flag||epage===cpage)&&butterfly_swiper_injector_config()</script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><script async src="//at.alicdn.com/t/font_2032782_8d5kxvn09md.js"></script></body></html>