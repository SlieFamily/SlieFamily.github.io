<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"><title>crawler爬虫进阶|Scrapy框架 | SLie's Blog|琴弦之轮</title><meta name="author" content="Slie"><meta name="copyright" content="Slie"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="简介  谈起爬虫必然要提起 Scrapy 框架，因为它能够帮助提升爬虫的效率，从而更好地实现爬虫。 Scrapy 是一个为了抓取网页数据、提取结构性数据而编写的应用框架，该框架是封装的，包含: request （异步调度和处理）、下载器（多线程的 Downloader）、解析器（selector）和"><link rel="shortcut icon" href="/img/%E7%A3%81%E5%B8%A6.png"><link rel="canonical" href="https://qslie.top/posts/87673eaa/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//fonts.googleapis.com" crossorigin=""><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="/pluginsSrc/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="/pluginsSrc/node-snackbar/dist/snackbar.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@900&amp;display=swap" media="print" onload='this.media="all"'><script>const GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:{path:"/search.xml",preload:!0,top_n_per_article:1,unescape:!1,languages:{hits_empty:"找不到您查询的内容：${query}",hits_stats:"共找到 ${hits} 篇文章"}},translate:void 0,noticeOutdate:{limitDay:90,position:"top",messagePrev:"本文章距离上次修改已经过了",messageNext:"天，相关内容可能不再适用，请留意."},highlight:{plugin:"highlighjs",highlightCopy:!0,highlightLang:!0,highlightHeightLimit:200},copy:{success:"复制成功",error:"复制错误",noSupport:"浏览器不支持"},relativeDate:{homepage:!1,post:!0},runtime:"天",dateSuffix:{just:"刚刚",min:"分钟前",hour:"小时前",day:"天前",month:"个月前"},copyright:void 0,lightbox:"mediumZoom",Snackbar:{chs_to_cht:"你已切换为繁体",cht_to_chs:"你已切换为简体",day_to_night:"你已切换为深色模式",night_to_day:"你已切换为浅色模式",bgLight:"#49b1f5",bgDark:"#121212",position:"bottom-center"},source:{justifiedGallery:{js:"/pluginsSrc/flickr-justified-gallery/dist/fjGallery.min.js",css:"/pluginsSrc/flickr-justified-gallery/dist/fjGallery.css"}},isPhotoFigcaption:!1,islazyload:!1,isAnchor:!1,percent:{toc:!0,rightside:!1},autoDarkmode:!1}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"crawler爬虫进阶|Scrapy框架",isPost:!0,isHome:!1,isHighlightShrink:!1,isToc:!0,postUpdate:"2024-03-11 22:44:06"}</script><noscript><style>#nav{opacity:1}.justified-gallery img{opacity:1}#post-meta time,#recent-posts time{display:inline!important}</style></noscript><script>(e=>{e.saveToLocal={set:function(e,t,o){if(0===o)return;const n=864e5*o,a={value:t,expiry:(new Date).getTime()+n};localStorage.setItem(e,JSON.stringify(a))},get:function(e){const t=localStorage.getItem(e);if(!t)return;const o=JSON.parse(t);if(!((new Date).getTime()>o.expiry))return o.value;localStorage.removeItem(e)}},e.getScript=e=>new Promise(((t,o)=>{const n=document.createElement("script");n.src=e,n.async=!0,n.onerror=o,n.onload=n.onreadystatechange=function(){const e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(n.onload=n.onreadystatechange=null,t())},document.head.appendChild(n)})),e.getCSS=(e,t=!1)=>new Promise(((o,n)=>{const a=document.createElement("link");a.rel="stylesheet",a.href=e,t&&(a.id=t),a.onerror=n,a.onload=a.onreadystatechange=function(){const e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(a.onload=a.onreadystatechange=null,o())},document.head.appendChild(a)})),e.activateDarkMode=function(){document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")},e.activateLightMode=function(){document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#ffffff")};const t=saveToLocal.get("theme");"dark"===t?activateDarkMode():"light"===t&&activateLightMode();const o=saveToLocal.get("aside-status");void 0!==o&&("hide"===o?document.documentElement.classList.add("hide-aside"):document.documentElement.classList.remove("hide-aside"));/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)&&document.documentElement.classList.add("apple")})(window)</script><link rel="stylesheet" href="/css/custom.css" media="defer" onload='this.media="all"'><link rel="stylesheet" href="/css/fixed_comment.css" media="defer" onload='this.media="all"'><link rel="stylesheet" href="/css/twikoo_beautify.css" media="defer" onload='this.media="all"'><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/font-awesome-animation.min.css" media="defer" onload='this.media="all"'><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/tag_plugins.css" media="defer" onload='this.media="all"'><script src="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/carousel-touch.js"></script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://s1.ax1x.com/2022/04/09/Likong.png" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">182</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">98</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">45</div></a></div><hr class="custom-hr"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i> <span>声影</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/gallery/"><i class="fa-fw fas fa-images"></i> <span>相册</span></a></li><li><a class="site-page child" href="/films/"><i class="fa-fw fas fa-video"></i> <span>映像</span></a></li><li><a class="site-page child" href="/books/"><i class="fa-fw fas fa-book"></i> <span>图书</span></a></li><li><a class="site-page child" href="/games/"><i class="fa-fw fas fa-gamepad"></i> <span>游戏</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i> <span>友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i> <span>关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image:url('https://z3.ax1x.com/2021/04/17/c5P76I.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="SLie's Blog|琴弦之轮"><span class="site-name">SLie's Blog|琴弦之轮</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i> <span>搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i> <span>声影</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/gallery/"><i class="fa-fw fas fa-images"></i> <span>相册</span></a></li><li><a class="site-page child" href="/films/"><i class="fa-fw fas fa-video"></i> <span>映像</span></a></li><li><a class="site-page child" href="/books/"><i class="fa-fw fas fa-book"></i> <span>图书</span></a></li><li><a class="site-page child" href="/games/"><i class="fa-fw fas fa-gamepad"></i> <span>游戏</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i> <span>友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i> <span>关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">crawler爬虫进阶|Scrapy框架</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2020-05-10T09:58:13.000Z" title="发表于 2020-05-10 17:58:13">2020-05-10</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-03-11T14:44:06.481Z" title="更新于 2024-03-11 22:44:06">2024-03-11</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E4%BA%BA%E7%94%9F%E8%8B%A6%E7%9F%AD%E3%81%AEPython/">人生苦短のPython</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E4%BA%BA%E7%94%9F%E8%8B%A6%E7%9F%AD%E3%81%AEPython/%E7%88%AC%E8%99%AB/">爬虫</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">2.9k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>10分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" data-flag-title="crawler爬虫进阶|Scrapy框架"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><div class="top-img gist" style="background-image:url(https://z3.ax1x.com/2021/04/17/c5P76I.jpg)"></div><article class="post-content" id="article-container"><h2 id="简介">简介</h2><blockquote><p>谈起爬虫必然要提起 Scrapy 框架，因为它能够帮助提升爬虫的效率，从而更好地实现爬虫。</p><p>Scrapy 是一个为了抓取网页数据、提取结构性数据而编写的应用框架，该框架是封装的，包含:</p><p>request （异步调度和处理）、下载器（多线程的 Downloader）、解析器（selector）和 twisted（异步处理）等。</p><p>对于网站的内容爬取，其速度非常快捷。</p><p>官方文档：<a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/">https://docs.scrapy.org/en/latest/</a></p></blockquote><span id="more"></span><h2 id="安装">安装</h2><blockquote><p>一般推荐使用Anaconda一键安装</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install -c conda-forge scrapy</span><br></pre></td></tr></table></figure><p>这里给出常规<code>pip</code>安装的方法</p></blockquote><p>【强烈推荐】使用**虚拟环境(venv)**进行开发，关于虚拟环境的相关内容见文章:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install Scrapy</span><br></pre></td></tr></table></figure><p>如果遇见<code>Twisted</code>依赖包安装错误，这是因为包和python版本不匹配导致的。</p><p>可以进入镜像网站：<a target="_blank" rel="noopener" href="https://www.lfd.uci.edu/~gohlke/pythonlibs/#twisted">https://www.lfd.uci.edu/~gohlke/pythonlibs/#twisted</a> 选择符合自己型号和版本的<code>whl</code>文件进行下载</p><p>然后<code>cd</code>至下载目录，通过<code>pip install &lt;文件名.whl&gt;</code>的方法安装</p><p>之后继续<code>pip install Scrapy</code>即可。</p><h2 id="初始化">初始化</h2><blockquote><p>Scrapy提供了可操作性的 &quot;项目 模式&quot;对爬虫进行操作，避免了&quot;一串代码从头写到尾&quot;的各种弊端，符合模块化思想。</p></blockquote><h3 id="创建项目">创建项目</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject &lt;项目名称&gt;</span><br></pre></td></tr></table></figure><p><code>cd</code>进入项目所在路径后，执行命令以 <strong>创建爬虫</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy genspider &lt;爬虫名称&gt; &lt;爬虫的主要url&gt;</span><br></pre></td></tr></table></figure><h3 id="架构解释">架构解释</h3><ol><li><code>items.py</code>: 用来存放爬虫爬取下来<strong>数据的模型</strong></li><li><code>middlewares.py</code>: 用来存放各种中间件的文件</li><li><code>pipelines.py</code>: 用来将<code>items</code>的模型存储</li><li><code>settings.py</code>: 设置爬虫的一些配置信息（比如请求头、多久发送一次请求、<code>ip</code>代理池等）</li><li><code>scrapy.cfg</code>: 项目的<strong>配置文件</strong></li><li><code>spiders包</code>: 以后所有的爬虫，都是存放到这个里面</li></ol><h3 id="基础配置">基础配置</h3><p>进入<code>settings.py</code>，为了更好进行爬虫，我们需要进行如下设置</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 遵循 robots.txt 守则</span></span><br><span class="line"><span class="comment"># 默认为True，这里改为False</span></span><br><span class="line">ROBOTSTXT_OBEY = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置下载停顿时间</span></span><br><span class="line"><span class="comment"># 默认被注释，如果爬取网站分页过多，为了不对所爬取的网站服务器造成压力，一般设置延迟</span></span><br><span class="line">DOWNLOAD_DELAY = <span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义请求头</span></span><br><span class="line">DEFAULT_REQUEST_HEADERS = &#123;</span><br><span class="line">    <span class="comment"># 默认</span></span><br><span class="line">  <span class="string">&#x27;Accept&#x27;</span>: <span class="string">&#x27;text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;Accept-Language&#x27;</span>: <span class="string">&#x27;en&#x27;</span>,</span><br><span class="line">    <span class="comment"># 手动设置UA</span></span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.163 Safari/537.36&#x27;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开启 模型储存（如果没有保存数据的需求，可以保持注释）</span></span><br><span class="line"><span class="comment"># 这里以项目名为wxapp为例</span></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">   <span class="string">&#x27;wxapp.pipelines.WxappPipeline&#x27;</span>: <span class="number">300</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>由于Scrapy框架运行爬虫程序的方式是通过命令行窗口输入命令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl &lt;爬虫名称&gt;</span><br></pre></td></tr></table></figure><p>此处，我们直接通过python语法将其写入python文件之中，以便方便运行。</p><p>在<code>&lt;项目名称&gt;/&lt;项目名称&gt;/</code>下（与<code>spiders</code>文件夹同目录）新建文件<code>run.py</code>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> cmdline</span><br><span class="line"></span><br><span class="line">cmdline.execute(<span class="string">&quot;scrapy crawl &lt;爬虫名称&gt;&quot;</span>.split())</span><br><span class="line"><span class="comment"># 该语句中，.split()相当于将str字符串分割为字符串列表</span></span><br><span class="line"><span class="comment"># 等价于：</span></span><br><span class="line"><span class="comment"># cmdline.execute([&#x27;scrapy&#x27;,&#x27;crawl&#x27;,&#x27;&lt;爬虫名称&gt;&#x27;])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 注：上述语句中的尖括号不在实际代码中</span></span><br></pre></td></tr></table></figure><h3 id="具体使用">具体使用</h3><h4 id="发起POST请求">发起POST请求</h4><blockquote><p>有时候我们想要在请求数据的时候发送post请求，那么这时候需要使用Request 的子类<code>FormRequest</code> 来实现。</p><p>如果想要在爬虫一开始的时候就发送POST请求，那么就在爬虫类中重写<code>start. requests(self)</code> 方法，并且不再调用<code>start. urls</code>里的<code>url</code></p></blockquote><p>下面以 <strong>模拟登录</strong>人人影视为例，展示重写方法和发起POST请求的过程。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject rr_login</span><br><span class="line">...</span><br><span class="line">scrapy genspider rr &quot;http://www.rrys2019.com/&quot;</span><br></pre></td></tr></table></figure><p>进入<code>settings.py</code>设置好后</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># spiders/rr.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RrSpider</span>(scray.Spider):</span><br><span class="line">    name = <span class="string">&#x27;renren&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;http://www.rrys2019.com/&#x27;</span>]</span><br><span class="line">    start_urls = [<span class="string">&#x27;http://www.rrys2019.com/&#x27;</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#重写 开始方法(否则默认以get直接进入start_urls的地址，而不是登录)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">start_request</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 登录url</span></span><br><span class="line">        url = <span class="string">&quot;http://www.rrys2019.com/user/login&quot;</span></span><br><span class="line">        <span class="comment"># 设置登录数据</span></span><br><span class="line">        data = &#123;</span><br><span class="line">			<span class="string">&#x27;account&#x27;</span>: <span class="string">&#x27;yichuan@itd.cn&#x27;</span>,</span><br><span class="line">			<span class="string">&#x27;password&#x27;</span>: <span class="string">&#x27;pyTHON123&#x27;</span>,</span><br><span class="line">			<span class="string">&#x27;remember&#x27;</span>: <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">			<span class="string">&#x27;url_back&#x27;</span>: <span class="string">&#x27;http://www.rrys2019.com/&#x27;</span></span><br><span class="line">		&#125;</span><br><span class="line">        <span class="comment"># 发起请求(此处还设置了方法回调callback)</span></span><br><span class="line">        request = scrapy.FormRequest(url,formdata = data,callback = parse_page)</span><br><span class="line">        <span class="keyword">yield</span> request</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># 设置 解析页面数据的方法</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse_page</span>(<span class="params">self,response</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;登录成功&#x27;</span>)</span><br></pre></td></tr></table></figure><p>新建运行文件<code>run.py</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># run.py</span></span><br><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> cmdline</span><br><span class="line"></span><br><span class="line">cmdline.execute(<span class="string">&quot;scrapr crawl rr&quot;</span>.split())</span><br></pre></td></tr></table></figure><p>之后运行即可！</p><h2 id="CrawlSpider爬虫">CrawlSpider爬虫</h2><h3 id="简介-2">简介</h3><blockquote><p>Crawlspider是Spider的一个子类；</p><p>Spider类的设计原则是只爬取<code>start_url</code>列表中的网页，而CrawlSpider类定义了一些规则(rule)来提供跟进link的方便的机制，从爬取的网页中获取link并继续爬取的工作更适合。</p><p>后者更适用于分页爬取和整站爬取项目</p></blockquote><h3 id="创建爬虫">创建爬虫</h3><blockquote><p>前提：已经通过命令<code>scrapy startproject</code>创建好了项目</p></blockquote><p><code>cd</code>至工程文件目录下，使用以下命令代替之前的创建爬虫的命令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy genspider -t crawl &lt;爬虫名称&gt; &lt;域名&gt;</span><br></pre></td></tr></table></figure><p>之后进入路径<code>../&lt;项目名称&gt;/&lt;项目爬虫&gt;/spiders/</code>下的爬虫文件<code>爬虫名称.py</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy.linkextractors <span class="keyword">import</span> LinkExtractor</span><br><span class="line"><span class="keyword">from</span> scrapy.spiders <span class="keyword">import</span> CrawlSpider, Rule</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">项目名称SpiderSpider</span>(<span class="title class_ inherited__">CrawlSpider</span>):</span><br><span class="line">    name = <span class="string">&#x27;爬虫名字&#x27;</span></span><br><span class="line">    <span class="comment"># url地址，以下以省略号带过</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;..&#x27;</span>]</span><br><span class="line">    start_urls = [<span class="string">&#x27;..&#x27;</span>]</span><br><span class="line">	</span><br><span class="line">    <span class="comment"># 定义匹配规则</span></span><br><span class="line">    rules = (</span><br><span class="line">        Rule(LinkExtractor(allow=<span class="string">r&#x27;Items/&#x27;</span>), callback=<span class="string">&#x27;parse_item&#x27;</span>, follow=<span class="literal">True</span>),</span><br><span class="line">    )</span><br><span class="line">	<span class="comment"># 解析数据(item可自定义)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse_item</span>(<span class="params">self, response</span>):</span><br><span class="line">        item = &#123;&#125;</span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure><h3 id="与Spider爬虫的区别">与Spider爬虫的区别</h3><ul><li>建立爬虫方式不同</li><li>spider有<code>parse</code>函数，每次爬虫运行时会自动运行，而crawlspider没有，可自行通过<code>callback</code>回调函数</li><li></li></ul><h4 id="Rule规则类">Rule规则类</h4><h4 id="链接提取器LinkExtractors">链接提取器LinkExtractors</h4><h4></h4><h2 id="Scrapy-Shell">Scrapy Shell</h2><blockquote><p>我们一般在爬虫中使用<code>xpath</code>、<code>beautifulsoup</code>、 正则表达式、<code>css</code>选择器等来提取想要的数据。</p><p>但是因为<code>scrapy</code> 是个比较&quot;重&quot;的框架。每次运行起来都要等待一段时间。因此要去验证我们写的提取规则是否正确，是一个比较麻烦的事情。</p><p>所以Scrapy 提供了一个shell,用来方便测试规则。当然也不仅仅局限于这一个功能。</p></blockquote><p>项目文件下，CMD内直接通过命令加想测试的url地址即可：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy shell &lt;url&gt;</span><br></pre></td></tr></table></figure><p>之后可通过python语法，按照自己的想法选取数据即可返回结果，用于测试规则是很方便的。如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>title = response.xpath(<span class="string">&#x27;//div[@class=&quot;dashabi&quot;]//a/text()&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>title</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>……</span><br></pre></td></tr></table></figure><p>除此之外，该shell也可以查看到我们<code>settings</code>中的各种设置等等</p><h2 id="下载文件-图片">下载文件/图片</h2><blockquote><p>在爬虫基础篇中，我们已经给出了图片下载的方法。</p><p>其实，Scrapy集成有更加便捷和快速的方法以下载图片和文件。</p></blockquote><ul><li><strong>优点</strong>：<ul><li><strong>避免重新下载</strong>最近已经下载过的数据。</li><li>可以<strong>方便</strong>的<strong>指定</strong>文件存储的路径。</li><li>可以将下载的图片<strong>转换</strong>成通用的<strong>格式</strong>。比如<code>png</code>或<code>jpg</code>。</li><li>可以方便的生成缩略图。</li><li>可以方便的检测图片的宽和高，确保他们满足最小限制。</li><li><strong>异步</strong>下载,效率非常高。</li></ul></li></ul><h4 id="下载前提">下载前提</h4><ul><li><p>在<code>items.py</code>中，定义好的两个属性：<code>file_urls</code>（给出列表）和<code>files</code></p><p>如果是图片，则分别是<code>image_urls</code>和<code>images</code></p></li><li><p>文件下载完成后，系统会自动把文件下载的相关信息存储到<code>item</code>的<code>files</code> /<code>images</code>属性中。</p><p>比如下载路径、下载的ur和文件/图片的校验码等。</p></li><li><p>在配置文件<code>settings.py</code> 中配置<code>FILES_STORE</code>/<code>IMAGE_STORE</code> ,这个配置是用来设置文件/图片下载路径。</p></li><li><p>启动<code>pipeline</code> :在<code>ITEML PIPELINES</code>中设置<code>scrapy.pipelines.files.FilesPipeline:1</code>。</p><p>图片则是<code>scrapy.piplines.images.ImagespIPLINE:1</code>。</p></li></ul><h4 id="上手操作">上手操作</h4><p>以图片下载为例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># settings.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">    <span class="comment"># 打开会运行主文件内的WxaooPipline函数</span></span><br><span class="line">   <span class="string">&#x27;wxapp.pipelines.WxappPipeline&#x27;</span>: <span class="number">300</span>,</span><br><span class="line">    <span class="comment"># 设置如下</span></span><br><span class="line">   <span class="string">&#x27;scrapy.piplines.images.ImagespIPLINE&#x27;</span>: <span class="number">1</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在底部添加</span></span><br><span class="line">IMAGES_STORE = os.path.join(...)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># piplines.py</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="中间件">中间件</h2><h3 id="简介-3">简介</h3><blockquote></blockquote><h3 id="随机请求头">随机请求头</h3><h3 id="随机代理">随机代理</h3><h3 id="代理池">代理池</h3><h2 id="连接数据库">连接数据库</h2><ul><li><p>所需库<code>pymysql</code></p></li><li><p>安装方法：<code>pip install pymysql</code></p></li><li><p>更多相关知识，详见数据库专题文章</p></li></ul><blockquote><p>由于连接数据库一般是将数据保存的操作，所以我们将数据库的连接部分放在<code>piplines.py</code>文件中</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导包</span></span><br><span class="line"><span class="keyword">import</span> pymysql</span><br><span class="line"><span class="comment"># 在setting.py文件中，预先设置好相关信息，如host，port，user，passwd等</span></span><br><span class="line">form Yourcrawl.setting <span class="keyword">import</span> MYSQLDATA</span><br><span class="line"></span><br><span class="line"><span class="comment"># 此处是系统默认设置的管道对象，下面YourcrawlSpiderPipline中，Yourcrawl替换为自己的项目名称</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">YourcrawlSpiderPipine</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 设置表对象</span></span><br><span class="line">        self.conn = pymysql.connect(**MYSQLDATA)</span><br><span class="line">        <span class="comment"># 设置游标</span></span><br><span class="line">        self.cursor = self.conn.cursor()</span><br><span class="line">        <span class="comment"># 设置MySql语句</span></span><br><span class="line">        self._sql = <span class="literal">None</span></span><br><span class="line">    </span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sql</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 使用装饰器，将sql()方法伪装成类以实现调用</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self._sql:</span><br><span class="line">            self._sql=<span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">            [此处为mysql语法的语句，表示想对数据库进行的操作]</span></span><br><span class="line"><span class="string">            &#x27;&#x27;&#x27;</span></span><br><span class="line">            <span class="keyword">return</span> self._dql </span><br><span class="line">        <span class="keyword">return</span> self._sql</span><br><span class="line">        <span class="comment">#如果没有sql语句就创建语句，有就直接返回</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 系统默认的item处理方法</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_item</span>(<span class="params">self,item,spider</span>):</span><br><span class="line">        <span class="comment"># 通过游标，运行sql语句</span></span><br><span class="line">        self.cursor.execute(self.sql,(其他参数))</span><br><span class="line">        <span class="comment"># 此处的“其他参数”，其实是一个传递参数给self.sql的过程</span></span><br><span class="line">        <span class="comment"># 当self.sql中的sql语句需要传递参数以保存内容时，如：</span></span><br><span class="line">        <span class="comment"># insert into TEXT(id,name) values(%d,%s)</span></span><br><span class="line">        <span class="comment"># 在TEXT表内插入数据，id=1，name=&#x27;steve&#x27;.而1和steve可以在后面通过传参形式来补</span></span><br><span class="line">        <span class="comment"># 注意，传入的是元组</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 提交</span></span><br><span class="line">        self.conn.commit()</span><br><span class="line">        </span><br></pre></td></tr></table></figure><p>当然，可以根据自己的需求<strong>优化代码</strong>，如结合python中的<code>try-except</code>设置<code>savepoint</code>，<code>rollback</code>等</p><p>但是，当数据量过于庞大时，这种一个个数据进行存储的方式消耗内存，而且<strong>性能较差</strong>。</p><p>这时我们还可以借助<strong>异步</strong>库<code>twisted</code>(下载安装scrapy库时已集成)实现<a href="#twisted-sql">异步写入数据</a>！</p><h2 id="关于异步">关于异步</h2><h3 id="设置锁">设置锁</h3><p><span id="twisted-sql">   </span></p><h3 id="异步写入数据库">异步写入数据库</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># piplines.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pymysql</span><br><span class="line"><span class="keyword">from</span> twisted.enterprise <span class="keyword">import</span> adbapi</span><br><span class="line"><span class="keyword">from</span> pymysql <span class="keyword">import</span> cursors</span><br><span class="line"><span class="keyword">from</span> crawl.setting <span class="keyword">import</span> MYSQLDATA</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建新的类来对数据进行处理</span></span><br><span class="line"><span class="comment">#需要在setting.py中加入，并给出权重。当然，也可以直接在原class内改动</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">YourCrawlTwistedPipline</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="comment"># 初始化</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 新增数据库游标class为字典型</span></span><br><span class="line">        MYSQLDATA[<span class="string">&#x27;cursorclass&#x27;</span>] = cursors.DictCursor</span><br><span class="line">        <span class="comment"># 建立数据池</span></span><br><span class="line">        self.dbpool = adbapi.ConnectionPool(<span class="string">&#x27;pymysql&#x27;</span>, **MYSQLDATA)</span><br><span class="line">        <span class="comment"># 设置sql语句</span></span><br><span class="line">        self._sql = <span class="literal">None</span></span><br><span class="line">    </span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sql</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self._sql:</span><br><span class="line">            self._sql = <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">            [此处为mysql语法的语句，表示想对数据库进行的操作，如：]</span></span><br><span class="line"><span class="string">            INSERT INTO TEXT(id,name) VALUES(%d,%s)</span></span><br><span class="line"><span class="string">            &#x27;&#x27;&#x27;</span></span><br><span class="line">            <span class="keyword">return</span> self._sql</span><br><span class="line">        <span class="keyword">return</span> self._sql</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_item</span>(<span class="params">self,item,spider</span>):</span><br><span class="line">        <span class="comment"># 将名为inser_item的函数传递给runInteraction并实例化为defer使之进行异步操作</span></span><br><span class="line">        <span class="comment"># 否则如果直接使用，与之前的同步操作数据库无异</span></span><br><span class="line">        defer = self.dbpool.runInteraction(self.insert_item,item)</span><br><span class="line">        <span class="comment"># 当运行出错时，调用handle_error函数，显示错误信息</span></span><br><span class="line">    	defer.addErrback(self.handle_error,item,spider)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#通过runInteraction调用的函数，还需要接收dbpool中之前我们定义的游标类型，sursorclass</span></span><br><span class="line">    <span class="comment">#所以，此处参数还差一个cursor类型</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">insert_item</span>(<span class="params">self,cursor,item</span>):</span><br><span class="line">        cursor.execute(self.sql,(元组参数))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">handle_error</span>(<span class="params">self,error,item,spider</span>):</span><br><span class="line">        <span class="comment"># 当然，item和spider参数可以不传递，看需求</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;=&quot;</span>*<span class="number">50</span>,<span class="string">&#x27;!error!&#x27;</span>,<span class="string">&quot;=&quot;</span>*<span class="number">50</span>)</span><br><span class="line">        <span class="built_in">print</span>(error)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;=&quot;</span>*<span class="number">100</span>)</span><br></pre></td></tr></table></figure><h2 id="Selenium-爬虫">Selenium 爬虫</h2><h3 id="爬取ajax数据">爬取ajax数据</h3><h2 id="分布式爬虫">分布式爬虫</h2><h3 id="优点">优点</h3><h2 id="参考资料">参考资料</h2><p><a target="_blank" rel="noopener" href="https://www.jb51.net/article/186178.htm">1.pip安装scrapy提示Twisted错误问题</a></p></article><div class="post-copyright"><div class="post-copyright__title"><span class="post-copyright-info"><h>crawler爬虫进阶|Scrapy框架</h></span></div><div class="post-copyright__type"><span class="post-copyright-info"><a href="https://qslie.top/posts/87673eaa/">https://qslie.top/posts/87673eaa/</a></span></div><div class="post-copyright-m"><div class="post-copyright-m-info"><div class="post-copyright-a"><h>作者</h><div class="post-copyright-cc-info"><h>Slie</h></div></div><div class="post-copyright-c"><h>发布于</h><div class="post-copyright-cc-info"><h>2020-05-10</h></div></div><div class="post-copyright-u"><h>更新于</h><div class="post-copyright-cc-info"><h>2024-03-11</h></div></div><div class="post-copyright-c"><h>许可协议</h><div class="post-copyright-cc-info"><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a rel="noopener" target="_blank" title="CC BY-NC-SA 4.0" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a></div></div></div></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/python/">python</a><a class="post-meta__tags" href="/tags/%E7%88%AC%E8%99%AB/">爬虫</a><a class="post-meta__tags" href="/tags/SQL/">SQL</a><a class="post-meta__tags" href="/tags/Scrapy/">Scrapy</a></div><div class="post_share"><div class="social-share" data-image="https://z3.ax1x.com/2021/04/17/c5P76I.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="/pluginsSrc/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="/pluginsSrc/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><link rel="stylesheet" href="/css/coin.css" media="defer" onload='this.media="all"'><div class="post-reward"><button class="tip-button reward-button"><span class="tip-button__text">打赏</span><div class="coin-wrapper"><div class="coin"><div class="coin__middle"></div><div class="coin__back"></div><div class="coin__front"></div></div></div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat.png" target="_blank"><img class="post-qr-code-img" src="/img/wechat.png"></a><div class="post-qr-code-desc"></div></li><li class="reward-item"><a href="/img/alipay.png" target="_blank"><img class="post-qr-code-img" src="/img/alipay.png"></a><div class="post-qr-code-desc"></div></li></ul></div></button></div><audio id="coinAudio" src="https://npm.elemecdn.com/akilar-candyassets@1.0.16/audio/coin.mp3"></audio><script defer src="/js/coin.js"></script><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/e7eccccc/" title="Python进阶学习|数据可视化I"><img class="cover" src="https://z3.ax1x.com/2021/04/17/c5P76I.jpg" onerror='onerror=null,src="/img/404.jpg"' alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Python进阶学习|数据可视化I</div></div></a></div><div class="next-post pull-right"><a href="/posts/7a9bf465/" title="状压算法|二进制映射与集合幂集"><img class="cover" src="https://z3.ax1x.com/2021/04/17/c5iSpj.jpg" onerror='onerror=null,src="/img/404.jpg"' alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">状压算法|二进制映射与集合幂集</div></div></a></div></nav><hr class="custom-hr"><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i> <span>评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://s1.ax1x.com/2022/04/09/Likong.png" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"></div><div class="author-info__name">Slie</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">182</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">98</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">45</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/sliefamily"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://qm.qq.com/cgi-bin/qm/qr?k=1hPHFQqPhpkbBVYbFjRC4q8YQ-A72EFL&amp;noverify=0" target="_blank" title="QQ"><i class="fab fa-qq"></i></a><a class="social-icon" href="https://github.com/SlieFamily" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:sliewdyinwhite@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">秘密基地被发现啦！QAQ</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AE%80%E4%BB%8B"><span class="toc-number">1.</span> <span class="toc-text">简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E8%A3%85"><span class="toc-number">2.</span> <span class="toc-text">安装</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%9D%E5%A7%8B%E5%8C%96"><span class="toc-number">3.</span> <span class="toc-text">初始化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E9%A1%B9%E7%9B%AE"><span class="toc-number">3.1.</span> <span class="toc-text">创建项目</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9E%B6%E6%9E%84%E8%A7%A3%E9%87%8A"><span class="toc-number">3.2.</span> <span class="toc-text">架构解释</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE"><span class="toc-number">3.3.</span> <span class="toc-text">基础配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B7%E4%BD%93%E4%BD%BF%E7%94%A8"><span class="toc-number">3.4.</span> <span class="toc-text">具体使用</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8F%91%E8%B5%B7POST%E8%AF%B7%E6%B1%82"><span class="toc-number">3.4.1.</span> <span class="toc-text">发起POST请求</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#CrawlSpider%E7%88%AC%E8%99%AB"><span class="toc-number">4.</span> <span class="toc-text">CrawlSpider爬虫</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%80%E4%BB%8B-2"><span class="toc-number">4.1.</span> <span class="toc-text">简介</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E7%88%AC%E8%99%AB"><span class="toc-number">4.2.</span> <span class="toc-text">创建爬虫</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%8ESpider%E7%88%AC%E8%99%AB%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="toc-number">4.3.</span> <span class="toc-text">与Spider爬虫的区别</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Rule%E8%A7%84%E5%88%99%E7%B1%BB"><span class="toc-number">4.3.1.</span> <span class="toc-text">Rule规则类</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%93%BE%E6%8E%A5%E6%8F%90%E5%8F%96%E5%99%A8LinkExtractors"><span class="toc-number">4.3.2.</span> <span class="toc-text">链接提取器LinkExtractors</span></a></li><li class="toc-item toc-level-4"><a class="toc-link"><span class="toc-number">4.3.3.</span><span class="toc-text"></span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Scrapy-Shell"><span class="toc-number">5.</span> <span class="toc-text">Scrapy Shell</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6-%E5%9B%BE%E7%89%87"><span class="toc-number">6.</span> <span class="toc-text">下载文件&#x2F;图片</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%8B%E8%BD%BD%E5%89%8D%E6%8F%90"><span class="toc-number">6.0.1.</span> <span class="toc-text">下载前提</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%8A%E6%89%8B%E6%93%8D%E4%BD%9C"><span class="toc-number">6.0.2.</span> <span class="toc-text">上手操作</span></a></li></ol></li></ol><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%AD%E9%97%B4%E4%BB%B6"><span class="toc-number">7.</span> <span class="toc-text">中间件</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%80%E4%BB%8B-3"><span class="toc-number">7.1.</span> <span class="toc-text">简介</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E8%AF%B7%E6%B1%82%E5%A4%B4"><span class="toc-number">7.2.</span> <span class="toc-text">随机请求头</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E4%BB%A3%E7%90%86"><span class="toc-number">7.3.</span> <span class="toc-text">随机代理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%A3%E7%90%86%E6%B1%A0"><span class="toc-number">7.4.</span> <span class="toc-text">代理池</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BF%9E%E6%8E%A5%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="toc-number">8.</span> <span class="toc-text">连接数据库</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B3%E4%BA%8E%E5%BC%82%E6%AD%A5"><span class="toc-number">9.</span> <span class="toc-text">关于异步</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%BE%E7%BD%AE%E9%94%81"><span class="toc-number">9.1.</span> <span class="toc-text">设置锁</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BC%82%E6%AD%A5%E5%86%99%E5%85%A5%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="toc-number">9.2.</span> <span class="toc-text">异步写入数据库</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Selenium-%E7%88%AC%E8%99%AB"><span class="toc-number">10.</span> <span class="toc-text">Selenium 爬虫</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%88%AC%E5%8F%96ajax%E6%95%B0%E6%8D%AE"><span class="toc-number">10.1.</span> <span class="toc-text">爬取ajax数据</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E7%88%AC%E8%99%AB"><span class="toc-number">11.</span> <span class="toc-text">分布式爬虫</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%98%E7%82%B9"><span class="toc-number">11.1.</span> <span class="toc-text">优点</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="toc-number">12.</span> <span class="toc-text">参考资料</span></a></li></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/posts/d3d469f8/" title="Docker - 一步到位的应用部署与上线"><img src="https://jsd.onmicrosoft.cn/gh/SlieFamily/TempImages@main//Auto/docker.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="Docker - 一步到位的应用部署与上线"></a><div class="content"><a class="title" href="/posts/d3d469f8/" title="Docker - 一步到位的应用部署与上线">Docker - 一步到位的应用部署与上线</a><time datetime="2024-03-05T07:11:45.000Z" title="发表于 2024-03-05 15:11:45">2024-03-05</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/c1bb1ae1/" title="GFS - 谷歌的分布式文件存储系统"><img src="http://img.49you.com/20170303/58b8d6f32d651.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="GFS - 谷歌的分布式文件存储系统"></a><div class="content"><a class="title" href="/posts/c1bb1ae1/" title="GFS - 谷歌的分布式文件存储系统">GFS - 谷歌的分布式文件存储系统</a><time datetime="2024-03-05T04:04:07.000Z" title="发表于 2024-03-05 12:04:07">2024-03-05</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/f21b6bc8/" title="HuskyLab Servers 0x519 操作指南【自用】"><img src="https://jsd.onmicrosoft.cn/gh/SlieFamily/TempImages@main//Auto/husklab_bg.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="HuskyLab Servers 0x519 操作指南【自用】"></a><div class="content"><a class="title" href="/posts/f21b6bc8/" title="HuskyLab Servers 0x519 操作指南【自用】">HuskyLab Servers 0x519 操作指南【自用】</a><time datetime="2024-03-04T13:29:31.000Z" title="发表于 2024-03-04 21:29:31">2024-03-04</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/f7dae821/" title="【快速入门】集群资源管理调度系统 - Slurm"><img src="https://gitee.com/sliewdy/ImageURL-slie/raw/master/imagesNoT/QQ%E5%9B%BE%E7%89%8720210414005713.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="【快速入门】集群资源管理调度系统 - Slurm"></a><div class="content"><a class="title" href="/posts/f7dae821/" title="【快速入门】集群资源管理调度系统 - Slurm">【快速入门】集群资源管理调度系统 - Slurm</a><time datetime="2024-03-04T12:50:38.000Z" title="发表于 2024-03-04 20:50:38">2024-03-04</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/8cb817a9/" title="【最优化】Levenberg-Marquardt 算法"><img src="https://jsd.onmicrosoft.cn/gh/SlieFamily/TempImages@main//Auto/202401051550627.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="【最优化】Levenberg-Marquardt 算法"></a><div class="content"><a class="title" href="/posts/8cb817a9/" title="【最优化】Levenberg-Marquardt 算法">【最优化】Levenberg-Marquardt 算法</a><time datetime="2023-12-22T03:07:39.000Z" title="发表于 2023-12-22 11:07:39">2023-12-22</time></div></div></div></div></div></div></main><footer id="footer" style="background-image:url('https://z3.ax1x.com/2021/04/17/c5P76I.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2024 By Slie</div><div class="framework-info"><span>框架</span> <a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题</span> <a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Welcome to Chaos World!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/pluginsSrc/medium-zoom/dist/medium-zoom.min.js"></script><script src="/pluginsSrc/instant.page/instantpage.js" type="module"></script><script src="/pluginsSrc/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn(){"object"==typeof pangu?pangu.autoSpacingPage():getScript("/pluginsSrc/pangu/dist/browser/pangu.min.js").then((()=>{pangu.autoSpacingPage()}))}function panguInit(){GLOBAL_CONFIG_SITE.isPost&&panguFn()}document.addEventListener("DOMContentLoaded",panguInit)</script><div class="js-pjax"><link rel="stylesheet" href="/pluginsSrc/katex/dist/katex.min.css"><script src="/pluginsSrc/katex/dist/contrib/copy-tex.min.js"></script><script>document.querySelectorAll("#article-container span.katex-display").forEach((a=>{btf.wrap(a,"div",{class:"katex-wrap"})}))</script><script>(()=>{const e=document.querySelectorAll("#article-container .mermaid-wrap");if(0===e.length)return;const t=()=>{window.loadMermaid=!0;const t="dark"===document.documentElement.getAttribute("data-theme")?"dark":"default";Array.from(e).forEach(((e,n)=>{const d=e.firstElementChild,r="mermaid-"+n,a="%%{init:{ 'theme':'"+t+"'}}%%\n"+d.textContent,i=mermaid.render(r,a);var m;"string"==typeof i?(m=i,d.insertAdjacentHTML("afterend",m)):i.then((({svg:e})=>{d.insertAdjacentHTML("afterend",e)}))}))},n=()=>{window.loadMermaid?t():getScript("/pluginsSrc/mermaid/dist/mermaid.min.js").then(t)};btf.addModeChange("mermaid",t),window.pjax?n():document.addEventListener("DOMContentLoaded",n)})()</script><script>(()=>{const t=()=>{twikoo.init(Object.assign({el:"#twikoo-wrap",envId:"https://twikoo.qslie.top/",region:"",onCommentLoaded:function(){btf.loadLightbox(document.querySelectorAll("#twikoo .tk-content img:not(.tk-owo-emotion)"))}},null)),GLOBAL_CONFIG_SITE.isPost&&(()=>{const t=document.getElementById("twikoo-count");t&&twikoo.getCommentsCount({envId:"https://twikoo.qslie.top/",region:"",urls:[window.location.pathname],includeReply:!1}).then((function(o){t.textContent=o[0].count})).catch((function(t){console.error(t)}))})()},o=()=>{"object"!=typeof twikoo?getScript("/pluginsSrc/twikoo/dist/twikoo.all.min.js").then(t):setTimeout(t,0)};btf.loadComment(document.getElementById("twikoo-wrap"),o)})()</script></div><script async src="/js/diytitle.js"></script><script async src="//at.alicdn.com/t/font_2264842_3izu8i5eoc2.js"></script><script async src="/js/diytitle.js"></script><script data-pjax defer src="/js/fixed_comment.js"></script><canvas class="fireworks" mobile="false"></canvas><script src="/pluginsSrc/butterfly-extsrc/dist/fireworks.min.js"></script><script id="canvas_nest" defer color="0,0,255" opacity="0.7" zindex="-1" count="99" mobile="false" src="/pluginsSrc/butterfly-extsrc/dist/canvas-nest.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i> <span>数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div><script data-pjax>if(document.getElementById("recent-posts")&&"/"===location.pathname){var parent=document.getElementById("recent-posts"),child='<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="https://qslie.top/tags/算法/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 算法相关，编程实现 (60)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://qslie.top/tags/故事/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📒 杂谈日志，光影记录 (6)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://qslie.top/tags/日常/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">💡 记忆碎片，梦境显影 (36)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://qslie.top/tags/机器学习/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">💻 机器学习，数学规划 (35)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><a class="magnet_link_more"  href="https://qslie.top/tags" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';console.log("已挂载magnet"),parent.insertAdjacentHTML("afterbegin",child)}</script><style>#catalog_magnet{flex-wrap:wrap;display:flex;width:100%;justify-content:space-between;padding:10px 10px 0 10px;align-content:flex-start}.magnet_item{flex-basis:calc(50% - 5px);background:#f2f2f2;margin-bottom:10px;border-radius:8px;transition:all .2s ease-in-out}.magnet_item:hover{background:#b30070}.magnet_link_more{color:#555}.magnet_link{color:#000}.magnet_link:hover{color:#fff}@media screen and (max-width:600px){.magnet_item{flex-basis:100%}}.magnet_link_context{display:flex;padding:10px;font-size:16px;transition:all .2s ease-in-out}.magnet_link_context:hover{padding:10px 20px}</style><style></style><script data-pjax>function butterfly_swiper_injector_config(){var s=document.getElementById("recent-posts");console.log("已挂载butterfly_swiper"),s.insertAdjacentHTML("afterbegin",'<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="posts/4f5fd499/" alt=""><img width="48" height="48" src="https://jsd.onmicrosoft.cn/gh/SlieFamily/TempImages@main//Auto/20231030204417.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-03-11</span><a class="blog-slider__title" href="posts/4f5fd499/" alt="">Deep Neural Net | 多层感知机与神经网络入门</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="posts/4f5fd499/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="posts/9a95977b/" alt=""><img width="48" height="48" src="math-cover.jfif" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-03-11</span><a class="blog-slider__title" href="posts/9a95977b/" alt="">SLie的&quot;数学基础&quot;集装箱|Perhaps.Ver1.04</a><div class="blog-slider__text">好了，你已经学会1+1=2了，下面来证明一下广义黎曼猜想吧~</div><a class="blog-slider__button" href="posts/9a95977b/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="posts/4ea9ab3c/" alt=""><img width="48" height="48" src="https://jsd.onmicrosoft.cn/gh/SlieFamily/TempImages@main/Auto/202202232045587.jpeg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-03-11</span><a class="blog-slider__title" href="posts/4ea9ab3c/" alt="">算法分析与设计 &amp; 本站算法综述</a><div class="blog-slider__text">本文罗列了常见的经典问题和算法，以及主要的算法分析方法和设计方法</div><a class="blog-slider__button" href="posts/4ea9ab3c/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="posts/5ebaa4d9/" alt=""><img width="48" height="48" src="https://gitee.com/sliewdy/ImageURL-slie/raw/master/imagesNoT/QQ%E5%9B%BE%E7%89%8720210414005713.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-03-11</span><a class="blog-slider__title" href="posts/5ebaa4d9/" alt="">捣鼓程序时的各种【踩坑】【报错】全收录</a><div class="blog-slider__text">配置环境、安装库包等网上冲浪时遇见到的各式各样奇奇怪怪的Warning和Error，以及各种治标不治本或者又治标又治本的解决方案全记录（个人向）</div><a class="blog-slider__button" href="posts/5ebaa4d9/" alt="">详情   </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>')}for(var elist="undefined".split(","),cpage=location.pathname,epage="/",flag=0,i=0;i<elist.length;i++)cpage.includes(elist[i])&&flag++;("all"===epage&&0==flag||epage===cpage)&&butterfly_swiper_injector_config()</script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><script async src="//at.alicdn.com/t/font_2032782_8d5kxvn09md.js"></script></body></html>